{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch==1.12.1 in /Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages (from torch==1.12.1) (4.4.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchvision==0.13.1 in /Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages (0.13.1)\n",
      "Requirement already satisfied: requests in /Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages (from torchvision==0.13.1) (2.28.1)\n",
      "Requirement already satisfied: numpy in /Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages (from torchvision==0.13.1) (1.22.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages (from torchvision==0.13.1) (4.4.0)\n",
      "Requirement already satisfied: torch==1.12.1 in /Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages (from torchvision==0.13.1) (1.12.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages (from torchvision==0.13.1) (9.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages (from requests->torchvision==0.13.1) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages (from requests->torchvision==0.13.1) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages (from requests->torchvision==0.13.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages (from requests->torchvision==0.13.1) (3.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: Pillow==9.3.0 in /Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages (9.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.12.1\n",
    "!pip install torchvision==0.13.1\n",
    "!pip install Pillow==9.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.cn1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.cn2 = nn.Conv2d(16, 32, 3, 1)\n",
    "        self.dp1 = nn.Dropout2d(0.10)\n",
    "        self.dp2 = nn.Dropout2d(0.25)\n",
    "        self.fc1 = nn.Linear(4608, 64) # 4608 is basically 12 X 12 X 32\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.cn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.cn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dp1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc2(x)\n",
    "        op = F.log_softmax(x, dim=1)\n",
    "        return op\n",
    "    \n",
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_MODEL = \"./convnet.pth\"\n",
    "model.load_state_dict(torch.load(PATH_TO_MODEL, map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : __torch__.ConvNet,\n",
       "      %x.1 : Tensor):\n",
       "  %51 : Function = prim::Constant[name=\"log_softmax\"]()\n",
       "  %49 : int = prim::Constant[value=3]()\n",
       "  %33 : int = prim::Constant[value=-1]()\n",
       "  %26 : Function = prim::Constant[name=\"_max_pool2d\"]()\n",
       "  %20 : int = prim::Constant[value=0]()\n",
       "  %19 : NoneType = prim::Constant()\n",
       "  %7 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %6 : bool = prim::Constant[value=0]()\n",
       "  %17 : int = prim::Constant[value=2]() # /var/folders/gs/mjlw0j210yz02z4yrv9gshdm0000gq/T/ipykernel_13610/2721400238.py:16:28\n",
       "  %32 : int = prim::Constant[value=1]() # /var/folders/gs/mjlw0j210yz02z4yrv9gshdm0000gq/T/ipykernel_13610/2721400238.py:18:29\n",
       "  %cn1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"cn1\"](%self)\n",
       "  %x.5 : Tensor = prim::CallMethod[name=\"forward\"](%cn1, %x.1) # /var/folders/gs/mjlw0j210yz02z4yrv9gshdm0000gq/T/ipykernel_13610/2721400238.py:12:12\n",
       "  %x.9 : Tensor = prim::CallFunction(%7, %x.5, %6) # /var/folders/gs/mjlw0j210yz02z4yrv9gshdm0000gq/T/ipykernel_13610/2721400238.py:13:12\n",
       "  %cn2 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name=\"cn2\"](%self)\n",
       "  %x.13 : Tensor = prim::CallMethod[name=\"forward\"](%cn2, %x.9) # /var/folders/gs/mjlw0j210yz02z4yrv9gshdm0000gq/T/ipykernel_13610/2721400238.py:14:12\n",
       "  %x.17 : Tensor = prim::CallFunction(%7, %x.13, %6) # /var/folders/gs/mjlw0j210yz02z4yrv9gshdm0000gq/T/ipykernel_13610/2721400238.py:15:12\n",
       "  %18 : int[] = prim::ListConstruct(%17, %17)\n",
       "  %21 : int[] = prim::ListConstruct(%20, %20)\n",
       "  %23 : int[] = prim::ListConstruct(%32, %32)\n",
       "  %x.21 : Tensor = prim::CallFunction(%26, %x.17, %18, %19, %21, %23, %6, %6) # /var/folders/gs/mjlw0j210yz02z4yrv9gshdm0000gq/T/ipykernel_13610/2721400238.py:16:12\n",
       "  %dp1 : __torch__.torch.nn.modules.dropout.Dropout2d = prim::GetAttr[name=\"dp1\"](%self)\n",
       "  %x.25 : Tensor = prim::CallMethod[name=\"forward\"](%dp1, %x.21) # /var/folders/gs/mjlw0j210yz02z4yrv9gshdm0000gq/T/ipykernel_13610/2721400238.py:17:12\n",
       "  %x.29 : Tensor = aten::flatten(%x.25, %32, %33) # /var/folders/gs/mjlw0j210yz02z4yrv9gshdm0000gq/T/ipykernel_13610/2721400238.py:18:12\n",
       "  %fc1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc1\"](%self)\n",
       "  %x.33 : Tensor = prim::CallMethod[name=\"forward\"](%fc1, %x.29) # /var/folders/gs/mjlw0j210yz02z4yrv9gshdm0000gq/T/ipykernel_13610/2721400238.py:19:12\n",
       "  %x.37 : Tensor = prim::CallFunction(%7, %x.33, %6) # /var/folders/gs/mjlw0j210yz02z4yrv9gshdm0000gq/T/ipykernel_13610/2721400238.py:20:12\n",
       "  %dp2 : __torch__.torch.nn.modules.dropout.___torch_mangle_1.Dropout2d = prim::GetAttr[name=\"dp2\"](%self)\n",
       "  %x.41 : Tensor = prim::CallMethod[name=\"forward\"](%dp2, %x.37) # /var/folders/gs/mjlw0j210yz02z4yrv9gshdm0000gq/T/ipykernel_13610/2721400238.py:21:12\n",
       "  %fc2 : __torch__.torch.nn.modules.linear.___torch_mangle_2.Linear = prim::GetAttr[name=\"fc2\"](%self)\n",
       "  %x.45 : Tensor = prim::CallMethod[name=\"forward\"](%fc2, %x.41) # /var/folders/gs/mjlw0j210yz02z4yrv9gshdm0000gq/T/ipykernel_13610/2721400238.py:22:12\n",
       "  %op.1 : Tensor = prim::CallFunction(%51, %x.45, %32, %49, %19) # /var/folders/gs/mjlw0j210yz02z4yrv9gshdm0000gq/T/ipykernel_13610/2721400238.py:23:13\n",
       "  return (%op.1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripted_model.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  _0 = __torch__.torch.nn.functional._max_pool2d\n",
      "  _1 = __torch__.torch.nn.functional.log_softmax\n",
      "  cn1 = self.cn1\n",
      "  x0 = (cn1).forward(x, )\n",
      "  x1 = __torch__.torch.nn.functional.relu(x0, False, )\n",
      "  cn2 = self.cn2\n",
      "  x2 = (cn2).forward(x1, )\n",
      "  x3 = __torch__.torch.nn.functional.relu(x2, False, )\n",
      "  x4 = _0(x3, [2, 2], None, [0, 0], [1, 1], False, False, )\n",
      "  dp1 = self.dp1\n",
      "  x5 = (dp1).forward(x4, )\n",
      "  x6 = torch.flatten(x5, 1)\n",
      "  fc1 = self.fc1\n",
      "  x7 = (fc1).forward(x6, )\n",
      "  x8 = __torch__.torch.nn.functional.relu(x7, False, )\n",
      "  dp2 = self.dp2\n",
      "  x9 = (dp2).forward(x8, )\n",
      "  fc2 = self.fc2\n",
      "  x10 = (fc2).forward(x9, )\n",
      "  return _1(x10, 1, 3, None, )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(scripted_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(scripted_model, 'scripted_convnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_scripted_model = torch.jit.load('scripted_convnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"./digit_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(image):\n",
    "    gray_image = transforms.functional.to_grayscale(image)\n",
    "    resized_image = transforms.functional.resize(gray_image, (28, 28))\n",
    "    input_image_tensor = transforms.functional.to_tensor(resized_image)\n",
    "    input_image_tensor_norm = transforms.functional.normalize(input_image_tensor, (0.1302,), (0.3069,))\n",
    "    return input_image_tensor_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = image_to_tensor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code/__torch__/torch/nn/functional.py:57: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0458e+01, -1.3929e+01, -2.5733e-03, -8.8133e+00, -1.0267e+01,\n",
       "         -1.5833e+01, -1.2593e+01, -1.3940e+01, -6.0533e+00, -1.2960e+01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_scripted_model(input_tensor.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashish.jha/opt/anaconda3/envs/mastering_pytorch_7_chaps/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0458e+01, -1.3929e+01, -2.5733e-03, -8.8133e+00, -1.0267e+01,\n",
       "         -1.5833e+01, -1.2593e+01, -1.3940e+01, -6.0533e+00, -1.2960e+01]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_tensor.unsqueeze(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
