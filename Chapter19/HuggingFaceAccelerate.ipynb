{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d977e0-8760-46bb-b08f-b335fbeb5a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# Initialize the accelerator\n",
    "accelerator = Accelerator(cpu=False, mixed_precision=\"fp16\")\n",
    "\n",
    "# Loading a dataset from HuggingFace Datasets library\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "\n",
    "# Initializing a tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenizing and preparing the dataset for PyTorch\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Creating PyTorch DataLoader\n",
    "train_dataloader = torch.utils.data.DataLoader(tokenized_dataset['train'], batch_size=8, shuffle=True)\n",
    "eval_dataloader = torch.utils.data.DataLoader(tokenized_dataset['test'], batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de76a32-8fe4-43e0-9c17-f9b4ca259af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "\n",
    "# Load pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Move model to the device managed by Accelerator\n",
    "model, train_dataloader, eval_dataloader = accelerator.prepare(model, train_dataloader, eval_dataloader)\n",
    "\n",
    "# Optimizer and learning rate scheduler setup\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training loop using PyTorch\n",
    "for epoch in range(3):  # Train for 3 epochs as an example\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            labels = batch['label']\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "            total_correct += accelerator.gather(predictions.eq(labels)).sum().item()\n",
    "            total_samples += len(labels)\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f\"Epoch {epoch + 1} - Evaluation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ad201-d253-4c52-81b8-18885ea8c782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf97faf-eb1a-4c12-a97b-f107f53f05cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
